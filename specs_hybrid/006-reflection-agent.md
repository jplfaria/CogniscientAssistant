# Reflection Agent Specification

**Type**: Agent  
**Interactions**: Supervisor, Context Memory, Web Search, Generation Agent (receives hypotheses), Ranking Agent (provides reviews), Meta-review Agent (receives feedback)

## Prerequisites
- Read: [System Overview and Architecture](001-system-overview.md) (for understanding agent roles)
- Read: [Multi-Agent Framework](002-multi-agent-framework.md) (for task queue patterns)
- Read: [Generation Agent](005-generation-agent.md) (for hypothesis format)
- Understand: Hypothesis structure and research proposal format

## Behavior

The Reflection Agent simulates the role of a scientific peer reviewer, critically examining hypotheses and research proposals generated by the system. It conducts multiple types of reviews to assess correctness, quality, novelty, and safety of scientific hypotheses.

### Core Responsibilities
- Perform rigorous peer review of generated hypotheses
- Search and analyze relevant prior work via web search
- Verify novelty against existing literature
- Identify flaws in reasoning or experimental design
- Provide structured feedback for system improvement
- Filter out non-viable or unsafe hypotheses

### Review Process Flow
1. Receive hypothesis from task queue
2. Perform initial quick assessment (no external tools)
3. If passes initial review, conduct full review with literature search
4. Apply specialized review types as needed
5. Generate structured review output
6. Return review to Context Memory for other agents

## Inputs

### Primary Input: Hypothesis for Review
```python
class HypothesisForReview:
    hypothesis_id: str
    summary: str
    full_description: str
    experimental_protocol: str
    assumptions: List[str]
    supporting_evidence: List[str]
    category: str
    elo_rating: float  # Current rating if available
```

### Configuration from Research Plan
```python
class ReviewConfiguration:
    require_novelty: bool
    safety_review_required: bool
    domain_constraints: List[str]
    evaluation_criteria: Dict[str, float]  # weights for different criteria
    literature_repository: Optional[str]  # Custom literature source
```

### Feedback from Meta-review Agent
```python
class MetaReviewFeedback:
    common_issues: List[str]
    improvement_suggestions: List[str]
    prior_review_patterns: Dict[str, Any]
```

### Tournament State (for Recurrent Reviews)
```python
class TournamentContext:
    reviewed_hypotheses: List[str]
    recurring_issues: List[str]
    successful_patterns: List[str]
```

## Outputs

### Review Result
```python
class ReviewResult:
    hypothesis_id: str
    review_type: str  # "initial", "full", "deep_verification", etc.
    passed: bool
    
    # Core evaluation scores
    correctness_score: float  # 0-1
    quality_score: float      # 0-1
    novelty_score: float      # 0-1
    safety_score: float       # 0-1
    
    # Detailed feedback
    strengths: List[str]
    weaknesses: List[str]
    critical_flaws: List[str]  # Reasons for rejection
    suggestions: List[str]      # Improvement recommendations
    
    # Literature grounding
    relevant_papers: List[Citation]
    novelty_assessment: NoveltyReport
    
    # For specific review types
    assumptions_analysis: Optional[AssumptionsReport]
    observations_explained: Optional[ObservationsReport]
    simulation_results: Optional[SimulationReport]
```

### Novelty Report
```python
class NoveltyReport:
    known_aspects: List[str]
    novel_aspects: List[str]
    similar_work: List[Citation]
    novelty_justification: str
```

### Deep Verification Report
```python
class AssumptionsReport:
    assumptions: List[AssumptionAnalysis]
    fundamental_flaws: List[str]
    non_fundamental_issues: List[str]

class AssumptionAnalysis:
    assumption: str
    sub_assumptions: List[str]
    validity: bool
    evidence: List[str]
    impact_if_invalid: str
```

## Review Types

### 1. Initial Review
- **Purpose**: Quick assessment without external tools
- **Focus**: Basic correctness, obvious flaws, preliminary safety check
- **Decision**: Pass/Fail for further review
- **Speed**: Fast (no web search)

### 2. Full Review
- **Purpose**: Comprehensive evaluation with literature grounding
- **Tools**: Web search, literature analysis
- **Focus**: 
  - Correctness of assumptions and reasoning
  - Quality of experimental design
  - Novelty compared to existing work
  - Detailed safety assessment
- **Output**: Complete review with citations

### 3. Deep Verification Review
- **Purpose**: Decompose and validate fundamental assumptions
- **Process**:
  1. Break hypothesis into constituent assumptions
  2. Decompose each assumption into sub-assumptions
  3. Decontextualize and evaluate each independently
  4. Identify which flaws are fundamental vs. correctable
- **Output**: Detailed assumptions analysis

### 4. Observation Review
- **Purpose**: Assess if hypothesis explains existing phenomena
- **Process**:
  1. Search for relevant experimental observations
  2. Evaluate if hypothesis provides better explanation
  3. Identify long-tail observations it might explain
- **Output**: List of observations explained/not explained

### 5. Simulation Review
- **Purpose**: Step-wise simulation of proposed mechanism/experiment
- **Process**:
  1. Simulate the proposed mechanism of action
  2. Simulate experimental protocol execution
  3. Identify potential failure points
- **Assumption**: LLM has internal world model for simulation

### 6. Tournament/Recurrent Review
- **Purpose**: Adaptive review based on tournament history
- **Process**:
  1. Analyze patterns from previous reviews
  2. Focus on recurring issues
  3. Apply lessons from tournament debates
- **Output**: Context-aware review

## Interaction Patterns

### With Supervisor Agent
- Receives review tasks from queue
- Reports completion status
- Provides workload metrics

### With Context Memory
- Reads hypotheses to review
- Writes review results
- Accesses tournament state
- Retrieves meta-review feedback

### With Web Search Tool
- Queries for relevant literature
- Searches for prior work on hypothesis topic
- Finds experimental evidence
- Verifies novelty claims

### With Other Agents
- **Generation Agent**: Reviews its hypotheses
- **Ranking Agent**: Provides reviews for tournament
- **Meta-review Agent**: Receives aggregated feedback
- **Evolution Agent**: Informs hypothesis improvements

## Review Criteria

### Correctness
- Logical consistency of reasoning
- Validity of assumptions
- Accuracy of scientific facts
- Proper experimental design

### Quality
- Clarity of hypothesis statement
- Completeness of experimental protocol
- Feasibility of proposed experiments
- Potential impact if successful

### Novelty
- Uniqueness compared to existing work
- Advancement over current understanding
- Non-obvious insights
- Creative approach

### Safety
- Ethical considerations
- Potential for dual-use
- Biosafety concerns
- Regulatory compliance

## Error Handling

### Hypothesis Access Errors
- If hypothesis not found: Return error status
- If incomplete hypothesis: Review what's available, note gaps

### Web Search Failures
- Fallback to review without literature
- Note limitation in review output
- Attempt alternative search queries

### Review Timeout
- Return partial review if time limit exceeded
- Prioritize most critical aspects
- Flag as incomplete review

## Quality Requirements

### Review Consistency
- Apply criteria uniformly across hypotheses
- Maintain calibrated scoring
- Document reasoning for scores

### Literature Grounding
- Cite specific papers and findings
- Quote relevant passages
- Verify claims against sources

### Constructive Feedback
- Provide actionable suggestions
- Identify specific improvements
- Balance criticism with strengths

### Iterative Improvement
- Learn from meta-review feedback
- Adapt to domain-specific needs
- Refine review criteria over time

## Natural Language Examples

### Initial Review Request
"Review this hypothesis for drug repurposing in AML. Check for obvious flaws in reasoning and basic safety concerns. No need for literature search yet."

### Full Review with Novelty Focus
"Conduct a comprehensive review of this liver fibrosis target hypothesis. Search the literature thoroughly to verify its novelty. Pay special attention to similar approaches that may have been tried."

### Deep Verification for Complex Hypothesis
"This AMR mechanism hypothesis has many assumptions. Break it down into fundamental components and verify each assumption independently. Identify which assumptions are critical to the hypothesis validity."

### Observation-Driven Review
"Review whether this hypothesis can explain the paradoxical observations in recent CF-PICI studies. Search for experimental results that this mechanism might clarify."

## Success Criteria

### Review Quality
- Identifies genuine flaws in hypotheses
- Correctly assesses novelty vs. existing work
- Provides helpful improvement suggestions
- Maintains appropriate safety standards

### System Integration
- Reviews complete within time bounds
- Other agents can act on review feedback
- Tournament rankings reflect review quality
- Meta-review patterns improve future reviews

### Scientific Rigor
- Reviews meet peer-review standards
- Literature citations are accurate
- Safety concerns are properly identified
- Feedback leads to better hypotheses