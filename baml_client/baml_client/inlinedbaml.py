# ----------------------------------------------------------------------------
#
#  Welcome to Baml! To use this generated code, please run the following:
#
#  $ pip install baml
#
# ----------------------------------------------------------------------------

# This file was generated by BAML: please do not edit it. Instead, edit the
# BAML files and re-generate this code using: baml-cli generate
# baml-cli is available with the baml package.

_file_map = {

    "TEMPLATE.baml": "// BAML Function Template - CRITICAL FOR MODEL COMPATIBILITY\n// \n// This template MUST be used for all new BAML functions to ensure compatibility\n// with Claude and Gemini models, which require at least one user message.\n//\n// Created: 2025-01-22\n// Reason: Claude/Gemini fail with system-only messages, returning content as dict\n\n// Example 1: Simple Analysis Function Template\n// function ExampleAnalyzeContent(\n//   content: string @description(\"The content to analyze\"),\n//   criteria: string[] @description(\"Analysis criteria\")  \n// ) -> AnalysisResult {\n//   client ProductionClient\n//   \n//   prompt #\"\n//     {{ _.role(\"system\") }}\n//     You are an expert analyst capable of examining content across multiple dimensions.\n//     You provide structured, detailed analysis based on specified criteria.\n//     \n//     {{ _.role(\"user\") }}\n//     Please analyze the following content according to the specified criteria.\n//     \n//     Content to analyze:\n//     {{ content }}\n//     \n//     Analysis criteria:\n//     {{ criteria }}\n//     \n//     Provide a comprehensive analysis addressing each criterion.\n//   \"#\n// }\n\n// Example 2: Generation Function Template with Context\n// function ExampleGenerateContent(\n//   goal: string @description(\"The generation goal\"),\n//   context: Context @description(\"Additional context\"),\n//   strategy: string @description(\"Generation strategy to use\")\n// ) -> GeneratedContent {\n//   client ProductionClient\n//   \n//   prompt #\"\n//     {{ _.role(\"system\") }}\n//     You are an expert content generator with deep knowledge across\n//     multiple domains. You excel at creating novel, high-quality content\n//     that meets specific requirements while being creative and insightful.\n//     \n//     {{ _.role(\"user\") }}\n//     Generate content for the following goal.\n//     \n//     Goal: {{ goal }}\n//     \n//     Context:\n//     - Domain: {{ context.domain }}\n//     - Constraints: {{ context.constraints }}\n//     - Requirements: {{ context.requirements }}\n//     \n//     Strategy: {{ strategy }}\n//     \n//     Create content that is:\n//     1. Novel and engaging\n//     2. Accurate and well-researched\n//     3. Aligned with the stated goal\n//     4. Following all constraints\n//   \"#\n// }\n\n// Example 3: Evaluation Function Template\n// function ExampleEvaluateContent(\n//   content: Content @description(\"The content to evaluate\"),\n//   criteria: EvaluationCriteria @description(\"Criteria for evaluation\")\n// ) -> ContentReview {\n//   client ProductionClient\n//   \n//   prompt #\"\n//     {{ _.role(\"system\") }}\n//     You are a rigorous reviewer with expertise in evaluating content.\n//     You provide balanced, constructive feedback that identifies both\n//     strengths and weaknesses while suggesting improvements.\n//     \n//     {{ _.role(\"user\") }}\n//     Please evaluate the following content.\n//     \n//     Content Summary: {{ content.summary }}\n//     \n//     Detailed Content: {{ content.details }}\n//     \n//     Evaluation Criteria:\n//     - Quality weight: {{ criteria.quality_weight }}\n//     - Accuracy weight: {{ criteria.accuracy_weight }}\n//     - Relevance weight: {{ criteria.relevance_weight }}\n//     \n//     Provide a thorough evaluation addressing:\n//     1. Overall quality and clarity\n//     2. Accuracy and correctness\n//     3. Relevance to objectives\n//     4. Strengths and weaknesses\n//     5. Suggested improvements\n//   \"#\n// }\n\n// TEMPLATE RULES:\n// 1. ALWAYS use both {{ _.role(\"system\") }} and {{ _.role(\"user\") }}\n// 2. System role: General capabilities and expertise\n// 3. User role: Specific task request with parameters\n// 4. Put input parameters in the user section\n// 5. Be explicit about output format expectations\n// 6. Test with multiple models before deployment\n\n// Model-Specific Notes:\n// - o3 models: Use max_completion_tokens (NOT max_tokens)\n// - Claude models: Require user message, system content must be string\n// - Gemini models: Also require user message\n// - All models: Support both system and user roles\n\n// Common Mistakes to Avoid:\n// ❌ Using only system message\n// ❌ Putting all content in system role\n// ❌ Not including {{ _.role() }} markers\n// ❌ Assuming all models have same requirements",
    "clients-argo.baml": "// Argo Gateway clients for BAML\n// This file provides two approaches to connect to Argo\n\n// Approach 1: Using the fixed argo-proxy (official tool with bug fix)\nclient<llm> ArgoProxyFixed {\n  provider openai-generic\n  options {\n    base_url \"http://localhost:8000/v1\"\n    model \"gpt4o\"\n    api_key \"\"\n    headers {\n      \"x-argo-user\" env.ARGO_USER\n    }\n  }\n}\n\n// Approach 2: Using our custom proxy (CONCORDIA-style)\nclient<llm> ArgoCustomProxy {\n  provider openai-generic\n  options {\n    base_url \"http://localhost:8000/v1\"\n    model \"gpt4o\"\n    api_key \"\"\n  }\n}\n\n// Default Argo client (points to whichever is configured)\nclient<llm> ArgoDefault {\n  provider openai-generic\n  options {\n    base_url env.ARGO_PROXY_URL\n    model env.DEFAULT_MODEL\n    api_key \"\"\n  }\n}\n\n// Model-specific clients for testing\nclient<llm> ArgoGPT4 {\n  provider openai-generic\n  options {\n    base_url env.ARGO_PROXY_URL\n    model \"gpt4o\"\n    api_key \"\"\n  }\n}\n\nclient<llm> ArgoClaude {\n  provider openai-generic\n  options {\n    base_url env.ARGO_PROXY_URL\n    model \"claudeopus4\"\n    api_key \"\"\n  }\n}\n\nclient<llm> ArgoGemini {\n  provider openai-generic\n  options {\n    base_url env.ARGO_PROXY_URL\n    model \"gemini25pro\"\n    api_key \"\"\n  }\n}",
    "clients.baml": "// BAML Client Configuration for AI Co-Scientist\n// This file defines the LLM clients and their configurations\n\n// Mock client for testing purposes\nclient<llm> MockClient {\n  provider openai\n  options {\n    model \"gpt-3.5-turbo\"\n    base_url \"http://localhost:8000/v1\"  // Mock server endpoint\n    timeout_seconds 10  // Shorter timeout for mock\n  }\n}\n\n// Development client with basic configuration\nclient<llm> DevelopmentClient {\n  provider openai\n  options {\n    model \"gpt-3.5-turbo\"\n    temperature 0.7\n    max_tokens 2000\n    timeout_seconds 30\n  }\n}\n\n// Default client using environment variables\nclient<llm> DefaultClient {\n  provider openai\n  options {\n    model env.BAML_MODEL\n    base_url env.BAML_BASE_URL\n    api_key env.BAML_API_KEY\n  }\n}\n\n// Dynamic client for agent-specific models\nclient<llm> DynamicClient {\n  provider openai\n  options {\n    model env.AGENT_MODEL\n    base_url \"http://localhost:8000/v1\"  // Argo proxy\n    temperature 0.7\n    max_tokens 4000\n    timeout_seconds 60\n  }\n}\n\n// Argo Gateway Clients for each available model\n// IMPORTANT: gpto3 (o3) IGNORES max_tokens parameter\n// O3 requires max_completion_tokens but BAML doesn't support it yet\n// This is a known limitation - o3 responses may be longer than expected\nclient<llm> ArgoGPTo3 {\n  provider openai\n  options {\n    model \"gpto3\"\n    base_url \"http://localhost:8000/v1\"  // Argo proxy\n    // WARNING: max_tokens is IGNORED by o3 models\n    // O3 needs max_completion_tokens which BAML doesn't support\n    // Consider using shorter prompts or post-processing responses\n    max_tokens 4000  // This has NO EFFECT on o3 but required by BAML\n    timeout_seconds 60\n  }\n}\n\n// Argo Gateway Clients for each available model\nclient<llm> ArgoGPT4o {\n  provider openai\n  options {\n    model \"gpt4o\"\n    base_url \"http://localhost:8000/v1\"  // Argo proxy\n    temperature 0.7\n    max_tokens 4000\n    timeout_seconds 60\n  }\n}\n\nclient<llm> ArgoGPT35 {\n  provider openai\n  options {\n    model \"gpt35\"\n    base_url \"http://localhost:8000/v1\"  // Argo proxy\n    temperature 0.7\n    max_tokens 4000\n    timeout_seconds 60\n  }\n}\n\nclient<llm> ArgoClaudeOpus4 {\n  provider openai\n  options {\n    model \"claudeopus4\"\n    base_url \"http://localhost:8000/v1\"  // Argo proxy\n    temperature 0.7\n    max_tokens 4000\n    timeout_seconds 60\n  }\n}\n\nclient<llm> ArgoClaudeSonnet4 {\n  provider openai\n  options {\n    model \"claudesonnet4\"\n    base_url \"http://localhost:8000/v1\"  // Argo proxy\n    temperature 0.7\n    max_tokens 4000\n    timeout_seconds 60\n  }\n}\n\nclient<llm> ArgoGemini25Pro {\n  provider openai\n  options {\n    model \"gemini25pro\"\n    base_url \"http://localhost:8000/v1\"  // Argo proxy\n    temperature 0.7\n    max_tokens 4000\n    timeout_seconds 60\n  }\n}\n\n// Production client (uses model config)\nclient<llm> ProductionClient {\n  provider openai\n  options {\n    model env.DEFAULT_MODEL\n    base_url \"http://localhost:8000/v1\"  // Argo proxy\n    temperature 0.7\n    max_tokens 4000\n    timeout_seconds 60\n  }\n}\n\n// Test Clients for Different Scenarios\n\n// Client for testing error handling\nclient<llm> TestErrorClient {\n  provider openai\n  options {\n    model \"gpt-3.5-turbo\"\n    base_url \"http://localhost:8001/v1\"  // Non-existent server for errors\n    timeout_seconds 1  // Very short timeout to trigger errors\n  }\n}\n\n// Client for testing slow responses and timeouts\nclient<llm> TestSlowClient {\n  provider openai\n  options {\n    model \"gpt-3.5-turbo\"\n    base_url \"http://localhost:8000/v1\"\n    timeout_seconds 5  // Moderate timeout for testing\n    // Simulated slow response via mock server\n  }\n}\n\n// Client for testing rate limiting\nclient<llm> TestRateLimitedClient {\n  provider openai\n  options {\n    model \"gpt-3.5-turbo\"\n    base_url \"http://localhost:8000/v1\"\n    max_retries 5\n  }\n}\n\n// Client for testing context window limits\nclient<llm> TestContextClient {\n  provider openai\n  options {\n    model \"gpt-3.5-turbo\"\n    base_url \"http://localhost:8000/v1\"\n    max_tokens 100  // Small limit for testing\n  }\n}\n\n// Client with retry policies enabled\nclient<llm> TestRetryClient {\n  provider openai\n  options {\n    model \"gpt-3.5-turbo\"\n    base_url \"http://localhost:8000/v1\"\n    max_retries 3\n    exponential_backoff true\n  }\n}\n\n// Client with retries disabled\nclient<llm> TestNoRetryClient {\n  provider openai\n  options {\n    model \"gpt-3.5-turbo\"\n    base_url \"http://localhost:8000/v1\"\n    max_retries 0\n  }\n}\n\n// Test configurations would go here",
    "environment.baml": "// BAML Environment Variable Documentation\n// \n// This file documents the environment variables used by the AI Co-Scientist system.\n// BAML itself doesn't support environment variable configuration blocks,\n// so this is purely documentation.\n//\n// Required Environment Variables:\n// - ARGO_API_KEY: API key for Argo Gateway authentication (Phase 8)\n// - ARGO_USER: Username for Argo authentication (Phase 8)\n//\n// Optional Environment Variables:\n// - BAML_CLIENT_PROVIDER: LLM provider (\"openai\", \"anthropic\", \"custom\")\n// - BAML_MODEL: Default model name (e.g., \"gpt-3.5-turbo\")\n// - ARGO_GATEWAY_URL: URL for Argo Gateway (default: \"http://localhost:8050/v1\")\n// - DEFAULT_MODEL: Default model for all agents\n// - ENABLE_SAFETY_CHECKS: Enable safety checks (true/false)\n// - LOG_LEVEL: Logging level (DEBUG, INFO, WARNING, ERROR)\n// - MAX_CONCURRENT_AGENTS: Maximum concurrent agent executions\n// - AGENT_TIMEOUT_SECONDS: Timeout for agent operations\n//\n// Agent-Specific Model Overrides:\n// - SUPERVISOR_MODEL: Model for supervisor agent\n// - GENERATION_MODEL: Model for generation agent\n// - REFLECTION_MODEL: Model for reflection agent\n// - RANKING_MODEL: Model for ranking agent\n// - EVOLUTION_MODEL: Model for evolution agent\n// - PROXIMITY_MODEL: Model for proximity agent\n// - META_REVIEW_MODEL: Model for meta-review agent\n//\n// These environment variables should be set in your .env file or system environment\n// before running the AI Co-Scientist system.",
    "functions.baml": "// BAML Function Definitions for AI Co-Scientist\n// This file defines all LLM-based functions used by agents\n\n// ============================================================================\n// Hypothesis Generation Functions\n// ============================================================================\n\n// Generate a new hypothesis based on research goal and context\nfunction GenerateHypothesis(\n  goal: string @description(\"Research goal or objective\"),\n  constraints: string[] @description(\"Constraints to consider (ethical, practical, etc.)\"),\n  existing_hypotheses: Hypothesis[] @description(\"Already generated hypotheses to avoid duplication\"),\n  focus_area: string? @description(\"Specific area to focus on\"),\n  generation_method: string @description(\"Method to use: literature_based, debate, assumptions, or expansion\")\n) -> Hypothesis {\n  client ProductionClient\n  \n  prompt #\"\n    {{ _.role(\"system\") }}\n    You are a brilliant research scientist specialized in generating novel hypotheses.\n    You excel at creating scientifically plausible hypotheses that respect constraints while offering potential for significant discovery.\n    You always provide complete hypotheses with experimental protocols and supporting evidence.\n    \n    {{ _.role(\"user\") }}\n    Research Goal: {{ goal }}\n    \n    Constraints to consider:\n    {{ constraints }}\n    \n    {% if existing_hypotheses %}\n    Already explored hypotheses (avoid duplication):\n    {% for hyp in existing_hypotheses %}\n    - {{ hyp.summary }}\n    {% endfor %}\n    {% endif %}\n    \n    {% if focus_area %}\n    Focus Area: {{ focus_area }}\n    {% endif %}\n    \n    Generation Method: {{ generation_method }}\n    \n    Based on the {{ generation_method }} approach, generate a novel hypothesis that:\n    1. Addresses the research goal\n    2. Respects all constraints\n    3. Is scientifically plausible\n    4. Offers potential for significant discovery\n    5. Is distinct from existing hypotheses\n    \n    Provide a complete hypothesis with experimental protocol and supporting evidence.\n    \n    Respond in valid JSON format matching the Hypothesis schema:\n    {\n      \"id\": \"unique_identifier\",\n      \"summary\": \"brief hypothesis statement\",\n      \"full_description\": \"detailed description\",\n      \"category\": \"mechanistic/therapeutic/diagnostic/etc\",\n      \"novelty_claim\": \"what makes this novel\",\n      \"assumptions\": [\"key\", \"assumptions\"],\n      \"reasoning\": \"your reasoning process\",\n      \"experimental_protocol\": {\n        \"objective\": \"experimental objective\",\n        \"methodology\": \"detailed methodology\",\n        \"expected_outcomes\": [\"expected\", \"results\"],\n        \"required_resources\": [\"needed\", \"resources\"],\n        \"timeline\": \"estimated timeline\"\n      },\n      \"supporting_evidence\": [\"evidence\", \"points\"],\n      \"version\": 1\n    }\n  \"#\n}\n\n// ============================================================================\n// Hypothesis Evaluation Functions\n// ============================================================================\n\n// Evaluate a hypothesis from different perspectives\nfunction EvaluateHypothesis(\n  hypothesis: Hypothesis @description(\"The hypothesis to evaluate\"),\n  review_type: ReviewType @description(\"Type of review to perform\"),\n  evaluation_criteria: string[] @description(\"Specific criteria to evaluate against\"),\n  context: map<string, string>? @description(\"Additional context for evaluation\")\n) -> Review {\n  client ProductionClient\n  \n  prompt #\"\n    {{ _.role(\"system\") }}\n    You are an expert scientific reviewer specialized in {{ review_type }} reviews.\n    You provide thorough, quantitative evaluations with detailed feedback and specific improvement suggestions.\n    You assess hypotheses based on correctness, quality, novelty, safety, and feasibility.\n    \n    {{ _.role(\"user\") }}\n    Please evaluate the following hypothesis:\n    \n    Summary: {{ hypothesis.summary }}\n    Full Description: {{ hypothesis.full_description }}\n    Novelty Claim: {{ hypothesis.novelty_claim }}\n    \n    Assumptions:\n    {% for assumption in hypothesis.assumptions %}\n    - {{ assumption }}\n    {% endfor %}\n    \n    Experimental Protocol:\n    Objective: {{ hypothesis.experimental_protocol.objective }}\n    Methodology: {{ hypothesis.experimental_protocol.methodology }}\n    \n    Evaluation Criteria:\n    {{ evaluation_criteria }}\n    \n    {% if context %}\n    Additional Context:\n    {{ context }}\n    {% endif %}\n    \n    Perform a thorough {{ review_type }} review, providing:\n    1. Quantitative scores (0-1) for correctness, quality, novelty, safety, and feasibility\n    2. Detailed narrative feedback\n    3. Key strengths and weaknesses\n    4. Specific improvement suggestions\n    5. Your confidence level in this assessment\n    \n    {% if review_type == \"deep_verification\" %}\n    Additionally, decompose and evaluate each assumption for validity and criticality.\n    {% endif %}\n    \n    {% if review_type == \"simulation\" %}\n    Additionally, simulate the experimental mechanism step-by-step and identify potential failure points.\n    {% endif %}\n  \"#\n}\n\n// ============================================================================\n// Safety Check Functions\n// ============================================================================\n\n// Perform safety check on hypothesis or task\nfunction PerformSafetyCheck(\n  target_type: string @description(\"Type of item: hypothesis, task, or goal\"),\n  target_content: string @description(\"Content to check for safety\"),\n  trust_level: string @description(\"Trust level: high, medium, or low\"),\n  safety_criteria: string[] @description(\"Specific safety criteria to check\")\n) -> SafetyCheck {\n  client ProductionClient\n  \n  prompt #\"\n    {{ _.role(\"system\") }}\n    You are a safety evaluator for a scientific research system.\n    You assess content for ethical concerns, potential harm, resource misuse, goal alignment, and appropriateness.\n    You are appropriately cautious based on trust levels while avoiding being overly restrictive for legitimate scientific research.\n    \n    {{ _.role(\"user\") }}\n    Please perform a safety check on the following content:\n    \n    Item Type: {{ target_type }}\n    Trust Level: {{ trust_level }}\n    \n    Content to evaluate:\n    {{ target_content }}\n    \n    Safety Criteria to check:\n    {{ safety_criteria }}\n    \n    Evaluate the content for:\n    1. Ethical concerns\n    2. Potential for harm\n    3. Resource misuse\n    4. Goal alignment\n    5. Content appropriateness\n    \n    Provide a comprehensive safety assessment including:\n    - Overall safety level (safe, concerning, or blocked)\n    - Specific checks performed\n    - Any violations found\n    - Recommendations for addressing concerns\n    - The primary category of any safety issues\n  \"#\n}\n\n// ============================================================================\n// Hypothesis Comparison Functions\n// ============================================================================\n\n// Compare two hypotheses for ranking\nfunction CompareHypotheses(\n  hypothesis1: Hypothesis @description(\"First hypothesis\"),\n  hypothesis2: Hypothesis @description(\"Second hypothesis\"),\n  comparison_criteria: string[] @description(\"Criteria for comparison\"),\n  debate_context: string? @description(\"Context from ongoing debate if applicable\")\n) -> ComparisonResult {\n  client ProductionClient\n  \n  prompt #\"\n    {{ _.role(\"system\") }}\n    You are a scientific judge who fairly compares research hypotheses.\n    You evaluate based on scientific merit, novelty, feasibility, evidence support, and specified criteria.\n    You provide thorough comparisons with clear, unbiased reasoning.\n    \n    {{ _.role(\"user\") }}\n    Please compare these two hypotheses:\n    \n    Hypothesis 1 (ID: {{ hypothesis1.id }}):\n    {{ hypothesis1.summary }}\n    Novelty: {{ hypothesis1.novelty_claim }}\n    \n    Hypothesis 2 (ID: {{ hypothesis2.id }}):\n    {{ hypothesis2.summary }}\n    Novelty: {{ hypothesis2.novelty_claim }}\n    \n    Comparison Criteria:\n    {{ comparison_criteria }}\n    \n    {% if debate_context %}\n    Debate Context:\n    {{ debate_context }}\n    {% endif %}\n    \n    Compare these hypotheses and determine which is superior based on:\n    1. Scientific merit and rigor\n    2. Novelty and potential impact\n    3. Feasibility and testability\n    4. Evidence support\n    5. The specified comparison criteria\n    \n    Provide a fair, thorough comparison with clear reasoning.\n  \"#\n}\n\n// ============================================================================\n// Hypothesis Enhancement Functions\n// ============================================================================\n\n// Enhance or evolve a hypothesis\nfunction EnhanceHypothesis(\n  original_hypothesis: Hypothesis @description(\"Hypothesis to enhance\"),\n  enhancement_strategy: string @description(\"Strategy: refine, combine, simplify, or paradigm_shift\"),\n  feedback: string[]? @description(\"Feedback to incorporate\"),\n  complementary_hypothesis: Hypothesis? @description(\"For combination strategy\")\n) -> Hypothesis {\n  client ProductionClient\n  \n  prompt #\"\n    {{ _.role(\"system\") }}\n    You are a research scientist specialized in improving and evolving hypotheses.\n    You can refine, combine, simplify, or transform hypotheses while maintaining scientific rigor.\n    You incorporate feedback effectively and generate enhanced hypotheses that build on existing insights.\n    \n    {{ _.role(\"user\") }}\n    Please enhance the following hypothesis:\n    \n    Original Hypothesis:\n    {{ original_hypothesis.summary }}\n    {{ original_hypothesis.full_description }}\n    \n    Enhancement Strategy: {{ enhancement_strategy }}\n    \n    {% if feedback %}\n    Feedback to address:\n    {% for item in feedback %}\n    - {{ item }}\n    {% endfor %}\n    {% endif %}\n    \n    {% if complementary_hypothesis %}\n    Complementary Hypothesis (for combination):\n    {{ complementary_hypothesis.summary }}\n    {% endif %}\n    \n    Based on the {{ enhancement_strategy }} strategy:\n    \n    {% if enhancement_strategy == \"refine\" %}\n    Refine the hypothesis by addressing weaknesses and incorporating feedback while\n    maintaining its core insight.\n    {% elif enhancement_strategy == \"combine\" %}\n    Combine the original and complementary hypotheses into a unified, stronger hypothesis\n    that leverages insights from both.\n    {% elif enhancement_strategy == \"simplify\" %}\n    Simplify the hypothesis to its essential components, making it more elegant and testable\n    while preserving its key insights.\n    {% elif enhancement_strategy == \"paradigm_shift\" %}\n    Transform the hypothesis by challenging its fundamental assumptions and proposing\n    a radically different perspective on the same problem.\n    {% endif %}\n    \n    Generate an enhanced hypothesis that improves upon the original.\n  \"#\n}\n\n// ============================================================================\n// Semantic Similarity Functions\n// ============================================================================\n\n// Calculate semantic similarity between hypotheses\nfunction CalculateSimilarity(\n  hypothesis1: Hypothesis @description(\"First hypothesis\"),\n  hypothesis2: Hypothesis @description(\"Second hypothesis\"),\n  similarity_aspects: string[] @description(\"Aspects to compare: mechanism, domain, methodology\")\n) -> SimilarityScore {\n  client ProductionClient\n  \n  prompt #\"\n    {{ _.role(\"system\") }}\n    You are an expert at analyzing semantic similarity between research hypotheses.\n    You provide precise similarity scores and identify shared concepts, mechanisms, and key differences.\n    You evaluate similarity on a 0-1 scale where 0 is completely different and 1 is nearly identical.\n    \n    {{ _.role(\"user\") }}\n    Please analyze the similarity between these two hypotheses:\n    \n    Hypothesis 1:\n    {{ hypothesis1.summary }}\n    Category: {{ hypothesis1.category }}\n    \n    Hypothesis 2:\n    {{ hypothesis2.summary }}\n    Category: {{ hypothesis2.category }}\n    \n    Analyze similarity across these aspects:\n    {{ similarity_aspects }}\n    \n    For each aspect, provide a similarity score (0-1) where:\n    - 0 = completely different\n    - 0.5 = some overlap\n    - 1 = nearly identical\n    \n    Also identify:\n    1. Shared concepts and mechanisms\n    2. Key differences\n    3. Overall semantic similarity\n    \n    Be precise in your similarity assessment.\n  \"#\n}\n\n// ============================================================================\n// Meta-Review Functions\n// ============================================================================\n\n// Extract patterns across multiple hypotheses and reviews\nfunction ExtractResearchPatterns(\n  hypotheses: Hypothesis[] @description(\"All hypotheses to analyze\"),\n  reviews: Review[] @description(\"All reviews to analyze\"),\n  focus: string @description(\"Focus area: methodology, assumptions, or themes\")\n) -> ResearchPatterns {\n  client ProductionClient\n  \n  prompt #\"\n    {{ _.role(\"system\") }}\n    You are an expert at meta-analysis of research hypotheses and reviews.\n    You identify recurring patterns, common strengths and weaknesses, emerging themes, and provide strategic recommendations.\n    You focus on actionable insights for improving the research process.\n    \n    {{ _.role(\"user\") }}\n    Please perform a meta-analysis of the following research corpus:\n    \n    Number of hypotheses: {{ hypotheses | length }}\n    Number of reviews: {{ reviews | length }}\n    Analysis Focus: {{ focus }}\n    \n    Hypothesis Categories:\n    {% for hyp in hypotheses %}\n    - {{ hyp.category }}: {{ hyp.summary }}\n    {% endfor %}\n    \n    Review Insights:\n    {% for review in reviews %}\n    - Type: {{ review.review_type }}, Decision: {{ review.decision }}\n      Key feedback: {{ review.key_strengths[0] if review.key_strengths else \"N/A\" }}\n    {% endfor %}\n    \n    Analyze the corpus to identify:\n    1. Recurring patterns in {{ focus }}\n    2. Common strengths that lead to positive reviews\n    3. Common weaknesses that need addressing\n    4. Emerging themes in the research\n    5. Strategic recommendations for future hypothesis generation\n    \n    Provide actionable insights for improving the research process.\n  \"#\n}\n\n// ============================================================================\n// Research Goal Parsing Functions\n// ============================================================================\n\n// Parse natural language research goal into structured format\nfunction ParseResearchGoal(\n  natural_language_goal: string @description(\"User's research goal in natural language\"),\n  domain_context: string? @description(\"Scientific domain if specified\")\n) -> ParsedResearchGoal {\n  client ProductionClient\n  \n  prompt #\"\n    {{ _.role(\"system\") }}\n    You are an expert at parsing natural language research goals into structured components.\n    You extract primary objectives, sub-objectives, constraints, relevant categories, key terms, and success criteria.\n    You are thorough but concise, and always respond in valid JSON format.\n    \n    {{ _.role(\"user\") }}\n    Please parse the following research goal:\n    \n    Research Goal: {{ natural_language_goal }}\n    {% if domain_context %}\n    Domain: {{ domain_context }}\n    {% endif %}\n    \n    Analyze this goal and extract:\n    1. The primary research objective (one clear statement)\n    2. Sub-objectives that support the main goal\n    3. Implied constraints (ethical, practical, scientific)\n    4. Relevant hypothesis categories (mechanistic, therapeutic, etc.)\n    5. Key scientific terms and concepts\n    6. Success criteria - what outcomes would satisfy this goal\n    \n    Be thorough but concise in your analysis.\n    \n    Respond in valid JSON format matching the ParsedResearchGoal schema:\n    {\n      \"primary_objective\": \"single clear statement\",\n      \"sub_objectives\": [\"array\", \"of\", \"objectives\"],\n      \"implied_constraints\": [\"ethical\", \"practical\", \"scientific\"],\n      \"hypothesis_categories\": [\"mechanistic\", \"therapeutic\", \"etc\"],\n      \"key_terms\": [\"important\", \"scientific\", \"terms\"],\n      \"success_criteria\": [\"measurable\", \"outcomes\"]\n    }\n  \"#\n}\n\n// Test blocks can be added later with correct BAML test syntax\n\n// Test configurations are in clients.baml\n",
    "generators.baml": "// BAML Generator Configuration\n// This file configures how BAML generates client code\n\ngenerator python {\n  output_type \"python/pydantic\"\n  output_dir \"../baml_client\"\n  version \"0.90.2\"\n}\n\n// Future generator configurations can be added here\n// For example:\n// generator typescript {\n//   output_type \"typescript\"\n//   output_dir \"../baml_client_ts\"\n// }",
    "models.baml": "// Core data models for AI Co-Scientist\n\n// Enums\n\nenum HypothesisCategory {\n    Mechanistic @alias(\"mechanistic\")\n    Therapeutic @alias(\"therapeutic\")\n    Diagnostic @alias(\"diagnostic\")\n    Biomarker @alias(\"biomarker\")\n    Methodology @alias(\"methodology\")\n    Other @alias(\"other\")\n}\n\nenum ReviewType {\n    Initial @alias(\"initial\")\n    Full @alias(\"full\")\n    DeepVerification @alias(\"deep_verification\")\n    Observation @alias(\"observation\")\n    Simulation @alias(\"simulation\")\n    Tournament @alias(\"tournament\")\n}\n\nenum ReviewDecision {\n    Accept @alias(\"accept\")\n    Reject @alias(\"reject\")\n    Revise @alias(\"revise\")\n}\n\nenum ConfidenceLevel {\n    High @alias(\"high\")\n    Medium @alias(\"medium\")\n    Low @alias(\"low\")\n}\n\nenum Validity {\n    Valid @alias(\"valid\")\n    Questionable @alias(\"questionable\")\n    Invalid @alias(\"invalid\")\n}\n\nenum Criticality {\n    Fundamental @alias(\"fundamental\")\n    Peripheral @alias(\"peripheral\")\n}\n\nenum SafetyLevel {\n    Safe @alias(\"safe\")\n    Concerning @alias(\"concerning\")\n    Blocked @alias(\"blocked\")\n}\n\nenum SafetyCategory {\n    ContentSafety @alias(\"content_safety\")\n    GoalViolation @alias(\"goal_violation\")\n    EthicalConcern @alias(\"ethical_concern\")\n    ResourceMisuse @alias(\"resource_misuse\")\n}\n\nenum TaskType {\n    GenerateHypothesis\n    ReflectOnHypothesis\n    RankHypotheses\n    EvolveHypothesis\n    FindSimilarHypotheses\n    MetaReview\n}\n\nenum TaskState {\n    Pending\n    Assigned\n    Executing\n    Completed\n    Failed\n}\n\nenum AgentType {\n    Generation\n    Reflection\n    Ranking\n    Evolution\n    Proximity\n    MetaReview\n    Supervisor\n}\n\nenum RequestType {\n    Generate\n    Analyze\n    Evaluate\n    Compare\n}\n\nenum ResponseStatus {\n    Success\n    Error\n    Partial\n}\n\n// Supporting Classes\n\nclass Citation {\n    authors string[] @description(\"List of authors\")\n    title string @description(\"Title of the publication\")\n    journal string? @description(\"Journal name, if applicable\")\n    year int @description(\"Publication year\")\n    doi string? @description(\"DOI identifier\")\n    url string? @description(\"URL to the publication\")\n}\n\nclass ExperimentalProtocol {\n    objective string @description(\"Main objective of the experiment\")\n    methodology string @description(\"Detailed methodology\")\n    required_resources string[] @description(\"Resources needed for the experiment\")\n    timeline string @description(\"Expected timeline for completion\")\n    success_metrics string[] @description(\"Metrics to measure success\")\n    potential_challenges string[] @description(\"Anticipated challenges\")\n    safety_considerations string[] @description(\"Safety considerations and precautions\")\n}\n\nclass HypothesisSummary {\n    core_idea string @description(\"The central idea in one sentence\")\n    scientific_impact string @description(\"Potential scientific impact\")\n    feasibility_assessment string @description(\"Assessment of feasibility\")\n    next_steps string[] @description(\"Recommended next steps\")\n}\n\n// Main Hypothesis Class\n\nclass Hypothesis {\n    id string @description(\"Unique identifier for the hypothesis\")\n    summary string @description(\"Concise one-sentence description\")\n    category string @description(\"Category of the hypothesis\")\n    full_description string @description(\"Detailed description of the hypothesis\")\n    novelty_claim string @description(\"What makes this hypothesis novel\")\n    assumptions string[] @description(\"Key assumptions made\")\n    experimental_protocol ExperimentalProtocol @description(\"Protocol for testing the hypothesis\")\n    supporting_evidence Citation[] @description(\"Supporting literature and evidence\")\n    confidence_score float @description(\"0-1 confidence score\")\n    generation_method string @description(\"Method used to generate this hypothesis\")\n    created_at string @description(\"Creation timestamp in ISO format\")\n    \n    // Optional tracking fields\n    elo_rating float? @description(\"Elo rating for tournament ranking\")\n    review_count int? @description(\"Number of reviews received\")\n    evolution_count int? @description(\"Number of times evolved\")\n}\n\n// Review-related Classes\n\nclass ReviewScores {\n    correctness float @description(\"0-1 score for scientific accuracy\")\n    quality float @description(\"0-1 score for rigor and completeness\")\n    novelty float @description(\"0-1 score for genuine advancement\")\n    safety float @description(\"0-1 score for ethical considerations\")\n    feasibility float @description(\"0-1 score for practical viability\")\n}\n\nclass AssumptionDecomposition {\n    assumption string @description(\"The assumption being evaluated\")\n    validity string @description(\"Assessment: valid, questionable, or invalid\")\n    evidence string @description(\"Evidence supporting the assessment\")\n    criticality string @description(\"Impact level: fundamental or peripheral\")\n}\n\nclass FailurePoint {\n    step string @description(\"Description of the step in the mechanism\")\n    probability float @description(\"0-1 probability of failure at this step\")\n    impact string @description(\"Description of impact if failure occurs\")\n}\n\nclass SimulationResults {\n    mechanism_steps string[] @description(\"Step-by-step breakdown of the mechanism\")\n    failure_points FailurePoint[] @description(\"Identified points of potential failure\")\n    predicted_outcomes string[] @description(\"Predicted experimental outcomes\")\n}\n\n// Main Review Class\n\nclass Review {\n    id string @description(\"Unique identifier for the review\")\n    hypothesis_id string @description(\"ID of the hypothesis being reviewed\")\n    reviewer_agent_id string @description(\"ID of the agent performing the review\")\n    review_type ReviewType @description(\"Type of review performed\")\n    decision ReviewDecision @description(\"Review decision: accept, reject, or revise\")\n    scores ReviewScores @description(\"Quantitative scoring across dimensions\")\n    \n    // Narrative components\n    narrative_feedback string @description(\"Detailed narrative review feedback\")\n    key_strengths string[] @description(\"Major strengths identified\")\n    key_weaknesses string[] @description(\"Major weaknesses identified\")\n    improvement_suggestions string[] @description(\"Specific suggestions for improvement\")\n    confidence_level string @description(\"Reviewer confidence: high, medium, or low\")\n    \n    // Optional review-type specific data\n    assumption_decomposition AssumptionDecomposition[]? @description(\"Deep verification analysis\")\n    simulation_results SimulationResults? @description(\"Results from simulation review\")\n    literature_citations Citation[]? @description(\"Supporting literature references\")\n    \n    // Metadata\n    created_at string @description(\"Review creation timestamp in ISO format\")\n    time_spent_seconds float? @description(\"Time spent on review in seconds\")\n}\n\n// Safety-related Classes\n\nclass SafetyCheck {\n    id string @description(\"Unique identifier for the safety check\")\n    target_type string @description(\"Type of item being checked (hypothesis, task, etc)\")\n    target_id string @description(\"ID of the item being checked\")\n    safety_level SafetyLevel @description(\"Overall safety assessment level\")\n    passed bool @description(\"Whether the item passed safety checks\")\n    checks_performed string[] @description(\"List of checks that were performed\")\n    \n    // Details about safety issues\n    violations string[]? @description(\"Specific safety violations found\")\n    recommendations string[]? @description(\"Recommendations for addressing safety concerns\")\n    category SafetyCategory? @description(\"Primary category of safety concern if any\")\n    \n    // Metadata\n    timestamp string @description(\"When the safety check was performed (ISO format)\")\n    metadata map<string, string>? @description(\"Additional context like trust level\")\n}\n\n// Task-related Classes\n\nclass Task {\n    id string @description(\"Unique identifier for the task\")\n    task_type TaskType @description(\"Type of task to be performed\")\n    priority int @description(\"Priority level, higher = more important\")\n    state TaskState @description(\"Current state of the task\")\n    payload map<string, string> @description(\"Task-specific data and parameters\")\n    \n    // Assignment info\n    assigned_to string? @description(\"ID of the worker/agent assigned to this task\")\n    \n    // Results\n    result map<string, string>? @description(\"Task execution result data\")\n    error string? @description(\"Error message if task failed\")\n    \n    // Timestamps\n    created_at string @description(\"Task creation timestamp in ISO format\")\n    assigned_at string? @description(\"When task was assigned (ISO format)\")\n    completed_at string? @description(\"When task completed/failed (ISO format)\")\n}\n\n// Agent Request/Response Classes\n\nclass RequestContent {\n    prompt string @description(\"Natural language instruction for the agent\")\n    context map<string, string> @description(\"Additional context including previous results, domain knowledge, constraints\")\n    parameters map<string, string> @description(\"Request parameters like max_length, temperature, response_format\")\n}\n\nclass AgentRequest {\n    request_id string @description(\"Unique identifier for the request\")\n    agent_type AgentType @description(\"Type of agent making the request\")\n    request_type RequestType @description(\"Type of request being made\")\n    content RequestContent @description(\"Request content and parameters\")\n}\n\nclass ResponseData {\n    content string @description(\"Generated or analyzed content\")\n    metadata map<string, string> @description(\"Response metadata including model_used, tokens_used, processing_time\")\n}\n\nclass ErrorInfo {\n    code string @description(\"Error type identifier\")\n    message string @description(\"Human-readable error description\")\n    recoverable bool @description(\"Whether the error is recoverable\")\n}\n\nclass AgentResponse {\n    request_id string @description(\"Matching input request ID\")\n    status ResponseStatus @description(\"Response status\")\n    response ResponseData? @description(\"Response data if successful\")\n    error ErrorInfo? @description(\"Error information if failed\")\n}\n\n// Additional classes for BAML functions\n\nclass ComparisonResult {\n    winner_id string @description(\"ID of the winning hypothesis\")\n    confidence float @description(\"Confidence in the comparison (0-1)\")\n    reasoning string @description(\"Detailed reasoning for the decision\")\n    strengths_h1 string[] @description(\"Key strengths of hypothesis 1\")\n    strengths_h2 string[] @description(\"Key strengths of hypothesis 2\")\n    decisive_factors string[] @description(\"Factors that determined the winner\")\n}\n\nclass SimilarityScore {\n    overall_similarity float @description(\"Overall similarity score (0-1)\")\n    aspect_scores map<string, float> @description(\"Similarity scores per aspect\")\n    shared_concepts string[] @description(\"Key concepts shared between hypotheses\")\n    key_differences string[] @description(\"Main differences identified\")\n}\n\nclass ResearchPatterns {\n    identified_patterns string[] @description(\"Key patterns identified\")\n    common_strengths string[] @description(\"Recurring strengths across hypotheses\")\n    common_weaknesses string[] @description(\"Recurring weaknesses\")\n    emerging_themes string[] @description(\"Emerging research themes\")\n    recommendations string[] @description(\"Strategic recommendations\")\n    synthesis_summary string @description(\"High-level synthesis of findings\")\n}\n\nclass ParsedResearchGoal {\n    primary_objective string @description(\"Main research objective\")\n    sub_objectives string[] @description(\"Broken down sub-objectives\")\n    implied_constraints string[] @description(\"Constraints inferred from the goal\")\n    suggested_categories string[] @description(\"Relevant hypothesis categories\")\n    key_terms string[] @description(\"Important scientific terms identified\")\n    success_criteria string[] @description(\"What would constitute success\")\n}",
}

def get_baml_files():
    return _file_map